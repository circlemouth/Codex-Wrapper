# Copy this file to `.env` and adjust values as needed.

# --- Authentication ---
# If set, requests must include `Authorization: Bearer <PROXY_API_KEY>`
PROXY_API_KEY=

# --- Rate limiting ---
# Requests allowed per minute per IP (0 to disable)
RATE_LIMIT_PER_MINUTE=60

# --- Codex CLI runtime ---
# Path to `codex` binary (in $PATH by default)
CODEX_PATH=codex

# Working directory where Codex can read/write
CODEX_WORKDIR=/workspace

# Optional: force a specific model (e.g. o3, o4-mini, gpt-5)
CODEX_MODEL=


# Sandbox mode for Codex CLI (read-only | workspace-write | danger-full-access)
CODEX_SANDBOX_MODE=read-only

# Reasoning effort for the model (minimal | low | medium | high)
CODEX_REASONING_EFFORT=medium

# Restrict remote model providers to LOCAL ONLY (true | false)
# Default and recommended: false (to use the built‑in OpenAI provider).
# Set true only if you want to hard‑enforce local providers (e.g., Ollama).
CODEX_LOCAL_ONLY=false

# Explicitly allow API requests to use sandbox_mode="danger-full-access"
# Default is false for safety. Set to true only in trusted containers/VMs.
CODEX_ALLOW_DANGER_FULL_ACCESS=false

# Server-side timeout for Codex execution (seconds)
CODEX_TIMEOUT=120

# --- Advanced ---
# To use a different env file than ".env", set this in the OS env
# BEFORE starting the server (do not put it inside .env):
#   export CODEX_ENV_FILE=.env.local
# CODEX_ENV_FILE=.env.local
